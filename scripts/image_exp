#!/bin/bash
#SBATCH --job-name= # TODO: Set your job name
#SBATCH --partition=             # TODO: Set your partition name
#SBATCH --nodes=                # TODO: Set your number of nodes
#SBATCH --ntasks-per-node=       # TODO: Set your number of tasks per node
#SBATCH --gres=gpu:          # TODO: Set your GPU type (h100:1, l40s:1, etc.)
#SBATCH --cpus-per-task=       # TODO: Set your number of CPUs per task
#SBATCH --mem=60G                # TODO: Set your memory per node
#SBATCH --array=0-47                    # TODO: Set your array range based on combinations
#SBATCH --time=25:59:59            # TODO: Set your time limit
#SBATCH --mail-type=begin,end,fail # TODO: Set your email notification type
#SBATCH --output=image_experiment%A_%a.out  # TODO: Set your output file name
#SBATCH --mail-user=YOUR_EMAIL@example.com    # TODO: Set your email

# TODO: Modify these paths for your environment
source ~/miniconda3/etc/profile.d/conda.sh    # TODO: Set your conda path
conda activate YOUR_ENV_NAME                   # TODO: Set your conda environment name

# TODO: Set your personal tokens and paths
export HUGGINGFACE_HUB_TOKEN="YOUR_HF_TOKEN"  # TODO: Set your HuggingFace token
export TOKENIZERS_PARALLELISM=false
export HF_HOME=/path/to/your/hf_cache          # TODO: Set your HF cache path
export PY=~/miniconda3/envs/YOUR_ENV/bin/python # TODO: Set your Python path
export PYTHONPATH=$PYTHONPATH:$(pwd)/..
export WANDB_ENTITY="YOUR_WANDB_ENTITY"       # TODO: Set your WandB entity
export WANDB_PROJECT="YOUR_PROJECT_NAME"      # TODO: Set your WandB project name

echo "==== ENVIRONMENT INFORMATION ===="
echo "Job ID: $SLURM_JOB_ID"
echo "Running on host: $(hostname)"
echo "Current working directory: $(pwd)"
echo "Python path: $PY"
echo "HF_HOME: $HF_HOME"
echo "CUDA devices: $CUDA_VISIBLE_DEVICES"
echo "WandB Entity: $WANDB_ENTITY"
echo "WandB Project: $WANDB_PROJECT"
date

# TODO: Define your experimental parameters
MODELS=("")      # TODO: Set your model list
DATASETS=("" "" "")    # TODO: Set your dataset list
SEEDS=(42)                          # TODO: Set your random seeds
MODES=("" "")                       # TODO: Set your training modes
BASELINE_LR="1e-5"                           # TODO: Set your baseline learning rate
WD=(0.01)                                    # TODO: Set your weight decay values
TRAIN_BATCH=(16)                             # TODO: Set your batch sizes
TOPK_RATIOS=()               # TODO: Set your topk ratios
ACTIVE_THRESHOLD=(0.01)                       # TODO: Set your activation thresholds
NUM_EPOCH=(10)                               # TODO: Set number of epochs
ACTIVE_SAMPLE_RATIO=(0.01)                   # TODO: Set your sample ratios
GRADIENT_ACCUMULATION_STEPS=(2)               # TODO: Set gradient accumulation

COMBINATIONS=()
for model in "${MODELS[@]}"; do
  for dataset in "${DATASETS[@]}"; do
    for seed in "${SEEDS[@]}"; do
      for mode in "${MODES[@]}"; do
        for wd in "${WD[@]}"; do
          for batch in "${TRAIN_BATCH[@]}"; do
            # Choose topk list based on mode
            if [[ "$mode" == "baseline" ]]; then
              TOPK_LIST=(0.3)  # Baseline doesn't use topk, but we need one value
            else
              TOPK_LIST=("${TOPK_RATIOS[@]}")
            fi
            
            for topk in "${TOPK_LIST[@]}"; do
              for threshold in "${ACTIVE_THRESHOLD[@]}"; do
                for epoch in "${NUM_EPOCH[@]}"; do
                  for sample_ratio in "${ACTIVE_SAMPLE_RATIO[@]}"; do
                    for ga_steps in "${GRADIENT_ACCUMULATION_STEPS[@]}"; do
                      # Set learning rate based on mode
                      if [[ "$mode" == "baseline" ]]; then
                        lr=$BASELINE_LR
                      else
                        lr="1e-5"  # TODO: Set your NS learning rate
                      fi
                      
                      # Build command
                      cmd="--model_name $model --dataset $dataset --modality image"
                      cmd="$cmd --learning_rate $lr --weight_decay $wd --batch_size $batch"
                      cmd="$cmd --threshold $threshold --num_epochs $epoch --mode $mode"
                      cmd="$cmd --gradient_accumulation_steps $ga_steps --topk_ratio $topk"
                      cmd="$cmd --sample_ratio $sample_ratio --seed $seed --schedule"
                      cmd="$cmd --use_wandb --wandb_project YOUR_PROJECT --wandb_entity YOUR_ENTITY"  # TODO: Set your WandB info
                      COMBINATIONS+=("$cmd")
                    done
                  done
                done
              done
            done
          done
        done
      done
    done
  done
done

# Run experiment
TOTAL_JOBS=${#COMBINATIONS[@]}
echo "Total number of job combinations: $TOTAL_JOBS"
echo "Array task ID: $SLURM_ARRAY_TASK_ID"

CMD="${COMBINATIONS[$SLURM_ARRAY_TASK_ID]}"
echo "Running: $PY ../train_classifier.py $CMD"
$PY ../train_classifier.py $CMD

IMAGE_STATUS=$?
echo "Image experiment exit status: $IMAGE_STATUS"
echo "Check WandB dashboard for results"